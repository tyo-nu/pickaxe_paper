{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E. Coli Met/Thermo Example\n",
    "This is a detailed example on how to use pickaxe and the filters it comes with to:\n",
    "1. Generate an expansion of E. Coli using Pickaxe Rules\n",
    "2. Apply Metabolomics/Thermodynamics Filters\n",
    "3. Produce Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minedatabase import pickaxe, rules\n",
    "from minedatabase.filters import MetabolomicsFilter, AtomicCompositionFilter\n",
    "from minedatabase.filters.feasibility import _get_feasibility, ReactionFeasibilityFilter\n",
    "from time import time\n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import multiprocessing as mp\n",
    "from math import ceil\n",
    "import pickle\n",
    "\n",
    "class StopWatch():\n",
    "    def __init__(self):\n",
    "        self._start = time()\n",
    "\n",
    "    def start(self):\n",
    "        self._start = time()\n",
    "\n",
    "    def tick(self):\n",
    "        return time() - self._start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generate or Load Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cores = 11\n",
    "n_rules = 50\n",
    "input_cpds = \"../data/ecocyc_smiles_sanitized_600.csv\"\n",
    "\n",
    "timer = StopWatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Intializing pickaxe object\n",
      "\n",
      "Done intializing pickaxe object\n",
      "----------------------------------------\n",
      "\n",
      "Loading ../data/ecoli_metab_100t300r200.pk pickled data.\n",
      "Loaded 21336 compounds\n",
      "Loaded 38175 reactions\n",
      "Loaded 50 operators\n",
      "Took 0.6575591564178467\n"
     ]
    }
   ],
   "source": [
    "pk = pickaxe.Pickaxe()\n",
    "pk.load_pickled_pickaxe(\"../data/ecoli_metab_100t300r200.pk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data\n",
    "Took ~1hr with 12 processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Intializing pickaxe object\n",
      "\n",
      "Done intializing pickaxe object\n",
      "----------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [15:26:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:26:24] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [15:26:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:26:24] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit ERROR: [15:26:26] Can't kekulize mol.  Unkekulized atoms: 2 5 6 7 8 9\n",
      "[15:26:26] Can't kekulize mol.  Unkekulized atoms: 2 5 6 7 8 9\n",
      "\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [15:26:26] Can't kekulize mol.  Unkekulized atoms: 2 4 5 6 8 11\n",
      "[15:26:26] Can't kekulize mol.  Unkekulized atoms: 2 4 5 6 8 11\n",
      "\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [15:26:26] Can't kekulize mol.  Unkekulized atoms: 1 5 9 10\n",
      "[15:26:26] Can't kekulize mol.  Unkekulized atoms: 1 5 9 10\n",
      "\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [15:26:26] Can't kekulize mol.  Unkekulized atoms: 1 5 6 10 11 12\n",
      "RDKit ERROR: \n",
      "[15:26:26] Can't kekulize mol.  Unkekulized atoms: 1 5 6 10 11 12\n",
      "\n",
      "RDKit ERROR: [15:26:26] Can't kekulize mol.  Unkekulized atoms: 1 5 6 9 10 11\n",
      "[15:26:26] Can't kekulize mol.  Unkekulized atoms: 1 5 6 9 10 11\n",
      "\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [15:26:26] Can't kekulize mol.  Unkekulized atoms: 1 5 6 7 8 9\n",
      "[15:26:26] Can't kekulize mol.  Unkekulized atoms: 1 5 6 7 8 9\n",
      "\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load compound: Nc1[nH]c(=O)c2[nH]c(=O)nc2[nH]1\n",
      "Warning: could not load compound: Nc1[nH]c(=O)c2c(C(=O)O)cnc2[nH]1\n",
      "Warning: could not load compound: Nc1[nH]c(=O)c2c(CF)cnc2[nH]1\n",
      "Warning: could not load compound: Nc1[nH]c(=O)c2ncnc2[nH]1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [15:26:28] Can't kekulize mol.  Unkekulized atoms: 3 5 6 7 8 9\n",
      "[15:26:28] Can't kekulize mol.  Unkekulized atoms: 3 5 6 7 8 9\n",
      "\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [15:26:28] Can't kekulize mol.  Unkekulized atoms: 2 4 6 7 8 9 10 11\n",
      "[15:26:28] Can't kekulize mol.  Unkekulized atoms: 2 4 6 7 8 9 10 11\n",
      "\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [15:26:28] Can't kekulize mol.  Unkekulized atoms: 3 5 6 7 8 9\n",
      "[15:26:28] Can't kekulize mol.  Unkekulized atoms: 3 5 6 7 8 9\n",
      "\n",
      "RDKit ERROR: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1908 compounds loaded...\n",
      "(1886 after removing stereochemistry)\n",
      "----------------------------------------\n",
      "Filtering Generation 0\n",
      "\n",
      "Filtering compounds based on match with metabolomics data.\n",
      "1886 of 1886 compounds selected after Metabolomics filtering of generation 0--took 0.0s.\n",
      "\n",
      "Done filtering Generation 0\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Filtering Generation 0\n",
      "\n",
      "Applying filter: Atomic Composition\n",
      "Filtering Generation 0 with atomic composition {'C': [0, 10]}.\n",
      "1330 of 1886 compounds remain after applying filter: Atomic Composition--took 0.01s.\n",
      "\n",
      "Done filtering Generation 0\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Expanding Generation 1\n",
      "\n",
      "Generation 1: 0 percent complete\n",
      "Generation 1: 10 percent complete\n",
      "Generation 1: 20 percent complete\n",
      "Generation 1: 30 percent complete\n",
      "Generation 1: 40 percent complete\n",
      "Generation 1: 50 percent complete\n",
      "Generation 1: 60 percent complete\n",
      "Generation 1: 70 percent complete\n",
      "Generation 1: 80 percent complete\n",
      "Generation 1: 90 percent complete\n",
      "Generation 1 finished in 428.7795536518097 s and contains:\n",
      "\t\t65423 new compounds\n",
      "\t\t93700 new reactions\n",
      "\n",
      "Done expanding Generation: 1.\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Filtering Generation 1\n",
      "\n",
      "Filtering compounds based on match with metabolomics data.\n",
      "1582 of 65437 compounds selected after Metabolomics filtering of generation 1--took 11.69s.\n",
      "\n",
      "Done filtering Generation 1\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Filtering Generation 1\n",
      "\n",
      "Applying filter: Atomic Composition\n",
      "Filtering Generation 1 with atomic composition {'C': [0, 10]}.\n",
      "1558 of 4789 compounds remain after applying filter: Atomic Composition--took 0.02s.\n",
      "\n",
      "Done filtering Generation 1\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Expanding Generation 2\n",
      "\n",
      "Generation 2: 0 percent complete\n",
      "Generation 2: 10 percent complete\n",
      "Generation 2: 20 percent complete\n",
      "Generation 2: 30 percent complete\n",
      "Generation 2: 40 percent complete\n",
      "Generation 2: 50 percent complete\n",
      "Generation 2: 60 percent complete\n",
      "Generation 2: 70 percent complete\n",
      "Generation 2: 80 percent complete\n",
      "Generation 2: 90 percent complete\n",
      "Generation 2 finished in 515.14950299263 s and contains:\n",
      "\t\t98005 new compounds\n",
      "\t\t154903 new reactions\n",
      "\n",
      "Done expanding Generation: 2.\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Filtering Generation 2\n",
      "\n",
      "Filtering compounds based on match with metabolomics data.\n",
      "19319 of 98005 compounds selected after Metabolomics filtering of generation 2--took 12.04s.\n",
      "\n",
      "Done filtering Generation 2\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "Filtering Generation 2\n",
      "\n",
      "Applying filter: Atomic Composition\n",
      "Filtering Generation 2 with atomic composition {'C': [0, 10]}.\n",
      "19319 of 23653 compounds remain after applying filter: Atomic Composition--took 0.1s.\n",
      "\n",
      "Done filtering Generation 2\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "timer.start()\n",
    "rule_io, correactant_list, _ = rules.metacyc_generalized(n_rules=n_rules)\n",
    "\n",
    "# Load Pickaxe\n",
    "pk = pickaxe.Pickaxe(coreactant_list=correactant_list, rule_list=rule_io, filter_after_final_gen=True)\n",
    "cpds = pk.load_compound_set(input_cpds)\n",
    "\n",
    "# Set up Metabolomics Filter\n",
    "metFilter = MetabolomicsFilter(\n",
    "    filter_name=\"ADP1_Metabolomics_Data\",\n",
    "    met_data_name=\"Ecoli Suaer Dataset\",\n",
    "    met_data_path=\"../data/sauer_100to300_r200.csv\",\n",
    "    possible_adducts=[\"[M+F]-\", \"[M-H]-\"],\n",
    "    mass_tolerance=0.001,\n",
    "    rt_predictor=None,\n",
    "    rt_threshold=4.5,\n",
    "    rt_important_features=None\n",
    ")\n",
    "pk.filters.append(metFilter)\n",
    "\n",
    "# Set up Atomic Composition\n",
    "atomic_composition_constraints = {\"C\": [0, 10]}\n",
    "atomicFilter = AtomicCompositionFilter(atomic_composition_constraints)\n",
    "pk.filters.append(atomicFilter)\n",
    "\n",
    "# Run Transformations\n",
    "pk.transform_all(processes=n_cores, generations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk.pickle_pickaxe(\"../data/ecoli_metab_100t300r200.pk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generate and Apply Filters\n",
    "Filters can be applied before or after Pickaxe. In this case they are applied afterwards to utilize the full generated network.\n",
    "\n",
    "The filters are applied in two steps:\n",
    "1. Feasibility Filter\n",
    "2. Thermodynamics Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Feasibility Filter\n",
    "The feasibility filter utilizes the DeepRFC code. Here we parallelize the application of this filter and get the feasibility of reactions. If reactions are unable to be predicted, they will also be deemed \"infeasible\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevbot/miniconda3/envs/comb/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "rf = ReactionFeasibilityFilter()\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "        \n",
    "n_processors = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Reactions to Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify and Analyze \"1st Gen\" Reactions\n",
    "This code can be run in jupyter, but is faster outside due to parallelization start method (spawn vs. fork).\n",
    "\n",
    "Took ~1.5 hours with 12 processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify and Analyze \"1st Gen\" Reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxn_1gen_set = set()\n",
    "for cpd in pk.compounds.values():\n",
    "    if cpd[\"Generation\"] == 1:\n",
    "        rxn_1gen_set.update(cpd[\"Product_of\"])\n",
    "\n",
    "rf_inputs, gen1_failed_reaction = rf._get_inputs(rxn_1gen_set, pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk data for parallelization\n",
    "n_processors = 12\n",
    "inputs = [*rf_inputs.keys()]\n",
    "n_vals = len(inputs)\n",
    "chunk_size = n_vals // n_processors + 1 if (add := (n_vals % n_processors) / n_processors) < 1 else ceil(add)\n",
    "chunked_vals = [*chunks(inputs,  chunk_size)]\n",
    "\n",
    "rf_input_list = []\n",
    "for chunk in chunked_vals:\n",
    "    rf_input_dict = {}\n",
    "    for r_id in chunk:\n",
    "        rf_input_dict[r_id] = rf_inputs[r_id]\n",
    "\n",
    "    rf_input_list.append(rf_input_dict,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen1_feas_results = {}\n",
    "with mp.Pool(n_processors) as pool:\n",
    "    i = 0\n",
    "    for res in pool.imap_unordered(_get_feasibility, rf_input_list):\n",
    "        print(\"res\", i)\n",
    "        i += 1\n",
    "        gen1_feas_results.update(res)\n",
    "\n",
    "pickle.dump(gen1_feas_results, open(\"./data/gen1_feas_results.pk\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Results Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feas_dict_dups = {key: val[2] for key, val in gen1_feas_results.items()}\n",
    "feas_dict_dups.update({key: \"infeasible\" for key in gen1_failed_reaction})\n",
    "\n",
    "# Create dictionary and take feasible if collision and one is feasible\n",
    "feas_dict = {}\n",
    "for rxn_id, feas in feas_dict_dups.items():\n",
    "    rxn_id = rxn_id.split(\"_\")[0]\n",
    "    if rxn_id not in feas_dict:\n",
    "        feas_dict[rxn_id] = feas\n",
    "    elif feas == \"feasible\":\n",
    "        feas_dict[rxn_id] = feas\n",
    "\n",
    "assert len(rxn_1gen_set) == len(feas_dict)\n",
    "\n",
    "pickle.dump(gen1_feas_results, open(\".data/gen1_feas_dict.pk\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify and Analyze \"2st Gen\" Reactions\n",
    "This code can be run in jupyter, but is faster outside due to parallelization start method (spawn vs. fork).\n",
    "\n",
    "Took ~3 hours with 12 processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify and Analyze \"1st Gen\" Reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxn_2gen_set = set()\n",
    "for cpd in pk.compounds.values():\n",
    "    if cpd[\"Generation\"] == 1:\n",
    "        rxn_2gen_set.update(cpd[\"Product_of\"])\n",
    "\n",
    "rf_inputs, gen2_failed_reaction = rf._get_inputs(rxn_2gen_set, pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk data for parallelization\n",
    "n_processors = 12\n",
    "inputs = [*rf_inputs.keys()]\n",
    "n_vals = len(inputs)\n",
    "chunk_size = n_vals // n_processors + 1 if (add := (n_vals % n_processors) / n_processors) < 1 else ceil(add)\n",
    "chunked_vals = [*chunks(inputs,  chunk_size)]\n",
    "\n",
    "rf_input_list = []\n",
    "for chunk in chunked_vals:\n",
    "    rf_input_dict = {}\n",
    "    for r_id in chunk:\n",
    "        rf_input_dict[r_id] = rf_inputs[r_id]\n",
    "\n",
    "    rf_input_list.append(rf_input_dict,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen2_feas_results = {}\n",
    "with mp.Pool(n_processors) as pool:\n",
    "    i = 0\n",
    "    for res in pool.imap_unordered(_get_feasibility, rf_input_list):\n",
    "        print(\"res\", i)\n",
    "        i += 1\n",
    "        gen2_feas_results.update(res)\n",
    "\n",
    "pickle.dump(gen1_feas_results, open(\"./data/gen2_feas_results.pk\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Results Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feas_dict_dups = {key: val[2] for key, val in gen2_feas_results.items()}\n",
    "feas_dict_dups.update({key: \"infeasible\" for key in gen2_failed_reaction})\n",
    "\n",
    "# Create dictionary and take feasible if collision and one is feasible\n",
    "feas_dict = {}\n",
    "for rxn_id, feas in feas_dict_dups.items():\n",
    "    rxn_id = rxn_id.split(\"_\")[0]\n",
    "    if rxn_id not in feas_dict:\n",
    "        feas_dict[rxn_id] = feas\n",
    "    elif feas == \"feasible\":\n",
    "        feas_dict[rxn_id] = feas\n",
    "\n",
    "assert len(rxn_1gen_set) == len(feas_dict)\n",
    "\n",
    "pickle.dump(gen1_feas_results, open(\".data/gen2_feas_dict.pk\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Calculate Thermodynamics Feasibility\n",
    "### Running Externally\n",
    "- Requires a local [equilibrator cache to run](https://equilibrator.readthedocs.io/en/latest/local_cache.html).\n",
    "- When using eQuilibrator to calculate the ∆G_rxn the code spawns multiple connections to a SQL server. If using postgres this process is much faster than using the SQLite default.\n",
    "- As a result, ecoli_rxnfeas_calculator.py is run seperately from the jupyter notebook, and a csv is read in with the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('comb')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48a7033078221f2502f6da428408cf80d42e69035aa53b03ff2300cf0aca12a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
